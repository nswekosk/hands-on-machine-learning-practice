{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnojd1eYeX/l17taiJDYT0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "giGCdbVfVHJc"
      },
      "outputs": [],
      "source": [
        "# create and train a voiting classifier in Sikit-Learn composed of randomForsest, VOtingClassifier, and Logisitic Regression\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = datasets.make_moons(n_samples=500, noise=.3, random_state=42);\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"lr\", log_clf),\n",
        "        (\"rd\", rnd_clf),\n",
        "        (\"sv\", svm_clf)\n",
        "    ],\n",
        "    voting=\"hard\"\n",
        ");\n",
        "\n",
        "voting_clf.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view the accuracy of each model\n",
        "from sklearn.metrics import accuracy_score;\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train);\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK9ytLkkZcJT",
        "outputId": "a08176c3-c946-4fff-e44e-b9b7305d0ea2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.8666666666666667\n",
            "RandomForestClassifier 0.9090909090909091\n",
            "SVC 0.9090909090909091\n",
            "VotingClassifier 0.9151515151515152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train an ensemble of 500 Decision Tree classifiers: each is trained on 100 training instances randomly sampled from the training set with replacement.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators=500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1\n",
        ");\n",
        "\n",
        "bag_clf.fit(X_train, y_train);\n",
        "y_pred = bag_clf.predict(X_test);\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sOpJXUgaC5R",
        "outputId": "dc7e9373-8ad4-45ca-80f8-981cf9d99590"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9272727272727272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a bagging classifer with out-of-bag evaluation\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators=500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    oob_score=True\n",
        ");\n",
        "bag_clf.fit(X_train, y_train);\n",
        "print(\"OOB Score:\", bag_clf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq86KgGXb5nL",
        "outputId": "d0a3b116-439d-4874-d113-854a1c4444b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9164179104477612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = bag_clf.predict(X_test);\n",
        "print(\"Prediction:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13c1dXdecsiN",
        "outputId": "f083070e-91d1-4020-8fea-5bed61086280"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0.9212121212121213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a random forest classifier (Baggling classifier with a decision tree classifier)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1);\n",
        "rnd_clf.fit(X_train, y_train);\n",
        "y_pred_rf = rnd_clf.predict(X_test);\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf));\n",
        "\n",
        "'''\n",
        "similar bagging classifier as the RandomForestClassifier above\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(\n",
        "        splitter=\"random\",\n",
        "        max_leaf_nodes=16\n",
        "    ),\n",
        "    n_estimators=500,\n",
        "    max_samples=1.0,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1\n",
        ");\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "TFWy-M-cc2iz",
        "outputId": "4ccd68c7-6b00-4477-92f8-2ab74648f8d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9212121212121213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsimilar bagging classifier as the RandomForestClassifier above\\n\\nbag_clf = BaggingClassifier(\\n    DecisionTreeClassifier(\\n        splitter=\"random\",\\n        max_leaf_nodes=16\\n    ),\\n    n_estimators=500,\\n    max_samples=1.0,\\n    bootstrap=True,\\n    n_jobs=-1\\n);\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the importance of each feature using a RandomForestClassifier\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris();\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1);\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"]);\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "  print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGuP88Z1dmEu",
        "outputId": "415ab5c6-85bd-4e2b-ba13-107069e56ce4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.09571711034942516\n",
            "sepal width (cm) 0.023808353529291677\n",
            "petal length (cm) 0.45641312029477576\n",
            "petal width (cm) 0.42406141582650747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train an AdaBoost classifier based on 200 decision stumps.\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200,\n",
        "    algorithm=\"SAMME.R\",\n",
        "    learning_rate=0.5\n",
        "\n",
        ");\n",
        "ada_clf.fit(X_train, y_train);\n",
        "y_pred = ada_clf.predict(X_test);\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z44vFpDle8mD",
        "outputId": "d2cfec23-51c4-477b-834e-b55206c1ee6d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.896969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate some random data\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
        "\n",
        "# Building 3 decision tree regressors that improve based on each others predictions (similar to Gradient descent)\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2);\n",
        "tree_reg1.fit(X, y);\n",
        "\n",
        "y2 = y - tree_reg1.predict(X);\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2);\n",
        "tree_reg2.fit(X, y2);\n",
        "\n",
        "y3 = y2 - tree_reg1.predict(X);\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2);\n",
        "tree_reg3.fit(X, y3);\n",
        "\n",
        "X_new = np.array([[0.8]])\n",
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
        "#print(\"Accuracy:\", accuracy_score(y_pred, y))"
      ],
      "metadata": {
        "id": "nKy7YZNWfsOG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the same thing, but using the GradientBoostRegressor ensemble\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0);\n",
        "gbrt.fit(X, y);"
      ],
      "metadata": {
        "id": "y0NBu-d3hLYh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a GBRT ensemble with 120 trees, then measure the validatin error at each stage of training to find the optimal number of trees, and finally train another GBRT ensemble using the optimal number of trees\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y);\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120);\n",
        "gbrt.fit(X_train, y_train);\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_esimtators = np.argmin(errors) + 1\n",
        "print(\"Best:\", bst_n_esimtators);\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_esimtators);\n",
        "gbrt_best.fit(X_train, y_train);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npRGcyMNiF1A",
        "outputId": "d6e3b846-058e-4409-d9d8-a9a4b2cae9f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do the same thin by stop training early when the validation error does not improve for five iterations in a row\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True);\n",
        "\n",
        "min_val_error = float(\"inf\");\n",
        "error_going_up = 0;\n",
        "for n_estimators in range(1, 120):\n",
        "  gbrt.n_estimators = n_estimators;\n",
        "  gbrt.fit(X_train, y_train)\n",
        "  y_pred = gbrt.predict(X_val);\n",
        "  val_error = mean_squared_error(y_val, y_pred);\n",
        "  if val_error < min_val_error:\n",
        "    min_val_error = val_error;\n",
        "    error_going_up = 0;\n",
        "  else:\n",
        "    error_going_up += 1\n",
        "    if error_going_up == 5:\n",
        "      print(\"Prediction:\", y_pred)\n",
        "      print(\"Val error:\", val_error)\n",
        "      break # early stopping\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reSr8MPejDMS",
        "outputId": "160a03dc-e123-4338-fb5f-c3ec6bcc7010"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [ 0.58019483 -0.0211741  -0.0211741   0.12181154  0.43810588  0.02957955\n",
            "  0.57717787  0.26424075  0.39928288  0.36148811 -0.0211741   0.34701674\n",
            "  0.18350373  0.15170877  0.63186196  0.06452096 -0.0211741   0.477411\n",
            "  0.68067178  0.477411    0.5994077   0.71977728  0.57991325 -0.0211741\n",
            "  0.26424075]\n",
            "Val error: 0.002367954226391026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the XG Boost regressor\n",
        "\n",
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor();\n",
        "xgb_reg.fit(X_train, y_train);\n",
        "\n",
        "y_pred = xgb_reg.predict(X_val);"
      ],
      "metadata": {
        "id": "B7Kspg1SkLgB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement XG Boost regressor, but stop early\n",
        "\n",
        "xgb_reg.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    eval_set=[(X_val, y_val)],\n",
        "    early_stopping_rounds=2\n",
        ");\n",
        "y_pred = xgb_reg.predict(X_val);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-PzQh68kw_8",
        "outputId": "dd627f96-91c5-47c6-fb3d-be96879fbba1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:0.23584\n",
            "[1]\tvalidation_0-rmse:0.17932\n",
            "[2]\tvalidation_0-rmse:0.13658\n",
            "[3]\tvalidation_0-rmse:0.10759\n",
            "[4]\tvalidation_0-rmse:0.08705\n",
            "[5]\tvalidation_0-rmse:0.07359\n",
            "[6]\tvalidation_0-rmse:0.06434\n",
            "[7]\tvalidation_0-rmse:0.05872\n",
            "[8]\tvalidation_0-rmse:0.05460\n",
            "[9]\tvalidation_0-rmse:0.05312\n",
            "[10]\tvalidation_0-rmse:0.05204\n",
            "[11]\tvalidation_0-rmse:0.05148\n",
            "[12]\tvalidation_0-rmse:0.05121\n",
            "[13]\tvalidation_0-rmse:0.05152\n",
            "[14]\tvalidation_0-rmse:0.05147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pslZW2yJlN3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}